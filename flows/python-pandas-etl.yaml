id: python-pandas-etl
namespace: company.team

description: Orchestrated ETL pipeline that fetches data via HTTP, cleans it with Pandas (Python 3.12), and outputs metrics.

tasks:
  # 1. EXTRACT: Use a Kestra Plugin to get real data (Addresses AJ's feedback)
  - id: fetch_orders
    type: io.kestra.plugin.core.http.Download
    uri: https://huggingface.co/datasets/kestra/datasets/raw/main/csv/orders.csv

  # 2. TRANSFORM: Process the data
  - id: transform_data
    type: io.kestra.plugin.scripts.python.Script
    containerImage: python:3.12-slim
    dependencies:
      - pandas
      - kestra
    # Orchestration: Pass the downloaded file from Task 1 into Task 2
    inputFiles:
      data.csv: "{{ outputs.fetch_orders.uri }}"
    script: |
      import pandas as pd
      from kestra import Kestra

      # Read the file downloaded by the previous task
      df = pd.read_csv("data.csv")

      # Clean: Convert columns and drop invalid rows
      df['total'] = pd.to_numeric(df['total'], errors='coerce')
      df.dropna(subset=['total'], inplace=True)

      # Aggregate: Calculate revenue per product
      summary = df.groupby('product_id')['total'].sum().to_dict()

      # 3. LOAD: Output data using the official library (Addresses Will's feedback)
      Kestra.outputs({'product_revenue': summary})
      
      print(f"ETL Complete. Processed {len(df)} valid orders.")
