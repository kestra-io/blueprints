id: airbyte-cloud-dbt-cloud
namespace: company.team

tasks:
  - id: data_ingestion
    type: io.kestra.plugin.core.flow.Parallel
    tasks:
      - id: salesforce
        type: io.kestra.plugin.airbyte.cloud.jobs.Sync
        connectionId: e3b1ce92-547c-436f-b1e8-23b6936c12ab

      - id: google_analytics
        type: io.kestra.plugin.airbyte.cloud.jobs.Sync
        connectionId: e3b1ce92-547c-436f-b1e8-23b6936c12cd

      - id: facebook_ads
        type: io.kestra.plugin.airbyte.cloud.jobs.Sync
        connectionId: e3b1ce92-547c-436f-b1e8-23b6936c12ef

  - id: dbt_cloud_job
    type: io.kestra.plugin.dbt.cloud.TriggerRun
    jobId: "396284"
    accountId: "{{ secret('DBT_CLOUD_ACCOUNT_ID') }}"
    token: "{{ secret('DBT_CLOUD_API_TOKEN') }}"
    wait: true

pluginDefaults:
  - type: io.kestra.plugin.airbyte.cloud.jobs.Sync
    values:
      token: "{{ secret('AIRBYTE_CLOUD_API_TOKEN') }}"

description: |
  This Kestra flow orchestrates a modern ELT pipeline by combining **Airbyte Cloud** for data ingestion and **dbt Cloud** for transformations.
  It enables teams to automatically extract data from multiple SaaS sources, centralize it in the warehouse, and transform it into analytics-ready datasets.
  This flow is suitable for production-grade analytics pipelines, enabling **near real-time ingestion** from SaaS tools and **trusted transformations** via dbt Cloud.
  It can be scheduled, triggered via upstream dependencies, or launched on demand to support reporting and analytics use cases.

extend:
  shortDescription: "This blueprint orchestrates a production-grade ETL pipeline by combining parallel SaaS data ingestion with analytics transformations, using Airbyte Cloud for."
  title: Build an ETL Pipeline with Airbyte Cloud and dbt Cloud for SaaS Analytics
  description: |
    This blueprint orchestrates a **production-grade ETL pipeline** by combining
    **parallel SaaS data ingestion** with **analytics transformations**, using
    Airbyte Cloud for extraction and dbt Cloud for modeling.

    It performs the following actions:

    - Runs multiple Airbyte Cloud syncs in parallel to ingest data from SaaS
      sources such as Salesforce, Google Analytics, and advertising platforms.
    - Waits for ingestion to complete before triggering a dbt Cloud job.
    - Executes transformations that convert raw ingested data into
      analytics-ready, modeled tables.
    - Ensures dependencies are respected so transformations always run on fresh
      data.

    This pattern is designed for **analytics engineering teams**, **data
    platform teams**, and **modern data stacks** building reliable ETL workflows
    with Airbyte and dbt Cloud.

    Configuration:
      - Add an Airbyte Cloud API token as a secret (`AIRBYTE_CLOUD_API_TOKEN`).
      - Add dbt Cloud credentials (`DBT_CLOUD_ACCOUNT_ID`,
        `DBT_CLOUD_API_TOKEN`) as secrets.
      - Replace the Airbyte `connectionId` values with those from your Airbyte
        Cloud workspace.
      - Replace the dbt Cloud `jobId` with the job responsible for transforming
        ingested data.
      - Optionally schedule this automation or trigger it on demand to support
        dashboards, reporting, or downstream data products.

    By orchestrating ingestion and transformation in a single automation, this
    blueprint ensures **fresh, consistent, and analytics-ready data** is
    available for reporting and decision-making.
  tags:
    - Data
  ee: false
  demo: false
  meta_description: |
    Build an ETL pipeline with Airbyte Cloud and dbt Cloud to ingest SaaS data and
    transform it into analytics-ready tables for modern data stacks.
